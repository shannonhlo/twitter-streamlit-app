{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python391jvsc74a57bd007a70a5077e9c9feae5d08fa41fc44d95abc22f10394969018e5e0f4ca96aa5b",
   "display_name": "Python 3.9.1 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Data cleaning goals\n",
    "* Exploration of amazon review data\n",
    "* Data cleaning and pre-processing for text analytics & sentiment analysis\n",
    "* credit: https://github.com/EnesGokceDS/Amazon_Reviews_NLP_Capstone_Project/blob/master/1_Data_cleaning_and_feature_extraction.ipynb"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Part 1: Load data\n",
    "* Load libraries\n",
    "* Load data\n",
    "* Quick exploration of data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package wordnet to\n[nltk_data]     C:\\Users\\domen\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import nltk as n\n",
    "from textblob import TextBlob\n",
    "\n",
    "n.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                             product  \\\n",
       "0  Furbo Dog Camera: Treat Tossing, Full HD WiFi ...   \n",
       "1  Furbo Dog Camera: Treat Tossing, Full HD WiFi ...   \n",
       "2  Furbo Dog Camera: Treat Tossing, Full HD WiFi ...   \n",
       "\n",
       "                                      date                             title  \\\n",
       "0  Reviewed in Canada on December 14, 2018                  Glorified Webcam   \n",
       "1    Reviewed in Canada on August 15, 2018               Recieved Used Item!   \n",
       "2       Reviewed in Canada on May 26, 2018  Furbo made miracle happen for me   \n",
       "\n",
       "   rating                                               body  \n",
       "0     2.0  I bought the Furbo as a birthday gift for my b...  \n",
       "1     1.0  Extremely disappointed. I recieved a Furbo tha...  \n",
       "2     5.0  Iâ€™ve been using furbo for 2.5 weeks now. It ha...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>product</th>\n      <th>date</th>\n      <th>title</th>\n      <th>rating</th>\n      <th>body</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Furbo Dog Camera: Treat Tossing, Full HD WiFi ...</td>\n      <td>Reviewed in Canada on December 14, 2018</td>\n      <td>Glorified Webcam</td>\n      <td>2.0</td>\n      <td>I bought the Furbo as a birthday gift for my b...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Furbo Dog Camera: Treat Tossing, Full HD WiFi ...</td>\n      <td>Reviewed in Canada on August 15, 2018</td>\n      <td>Recieved Used Item!</td>\n      <td>1.0</td>\n      <td>Extremely disappointed. I recieved a Furbo tha...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Furbo Dog Camera: Treat Tossing, Full HD WiFi ...</td>\n      <td>Reviewed in Canada on May 26, 2018</td>\n      <td>Furbo made miracle happen for me</td>\n      <td>5.0</td>\n      <td>Iâ€™ve been using furbo for 2.5 weeks now. It ha...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "# Get the amazon reviews data, store as pandas df\n",
    "df = pd.read_csv(\"dog-cameras-raw.csv\")\n",
    "df = pd.DataFrame(df)\n",
    "df.head(3) # show first row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 490 entries, 0 to 489\nData columns (total 5 columns):\n #   Column   Non-Null Count  Dtype \n---  ------   --------------  ----- \n 0   product  490 non-null    object\n 1   date     490 non-null    object\n 2   title    490 non-null    object\n 3   rating   490 non-null    object\n 4   text     490 non-null    object\ndtypes: object(5)\nmemory usage: 19.3+ KB\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                  product  \\\n",
       "count                                                 490   \n",
       "unique                                                  1   \n",
       "top     Furbo Dog Camera: Treat Tossing, Full HD WiFi ...   \n",
       "freq                                                  490   \n",
       "\n",
       "                                         date       title rating  \\\n",
       "count                                     490         490    490   \n",
       "unique                                    355         442      5   \n",
       "top     Reviewed in Canada on January 9, 2020  Five Stars    5.0   \n",
       "freq                                        7          15    347   \n",
       "\n",
       "                                                     text  \n",
       "count                                                 490  \n",
       "unique                                                490  \n",
       "top     Iâ€™m glad I got this, this is so great. Thanks 5/5  \n",
       "freq                                                    1  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>product</th>\n      <th>date</th>\n      <th>title</th>\n      <th>rating</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>490</td>\n      <td>490</td>\n      <td>490</td>\n      <td>490</td>\n      <td>490</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>1</td>\n      <td>355</td>\n      <td>442</td>\n      <td>5</td>\n      <td>490</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>Furbo Dog Camera: Treat Tossing, Full HD WiFi ...</td>\n      <td>Reviewed in Canada on January 9, 2020</td>\n      <td>Five Stars</td>\n      <td>5.0</td>\n      <td>Iâ€™m glad I got this, this is so great. Thanks 5/5</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>490</td>\n      <td>7</td>\n      <td>15</td>\n      <td>347</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# Rename body (review text) to text, ensure it is of type string\n",
    "df = df.rename(columns = {'body': 'text'}).astype(str)\n",
    "\n",
    "# Get info from df\n",
    "df.info()\n",
    "\n",
    "# Describe the df\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         null  percent\n",
       "product     0      0.0\n",
       "date        0      0.0\n",
       "title       0      0.0\n",
       "rating      0      0.0\n",
       "text        0      0.0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>null</th>\n      <th>percent</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>product</th>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>date</th>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>title</th>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>rating</th>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>text</th>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# Exploring missing values\n",
    "null_values = df.isna().sum()\n",
    "null_values = pd.DataFrame(null_values,columns=['null'])\n",
    "sum_tot = len(df)\n",
    "null_values['percent'] = null_values['null']/sum_tot*100\n",
    "round(null_values,3).sort_values('percent',ascending=False)"
   ]
  },
  {
   "source": [
    "## Part 2: Feature Extraction (before text cleaning)\n",
    "* Count of Stopwords\n",
    "* Count of Punctuation\n",
    "* Count of Hashtag characters\n",
    "* Count of Numeric characters\n",
    "* Count of Emojis & Emoticons"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to\n[nltk_data]     C:\\Users\\domen\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package wordnet to\n[nltk_data]     C:\\Users\\domen\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package punkt to\n[nltk_data]     C:\\Users\\domen\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     C:\\Users\\domen\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# Load libraries\n",
    "!pip install -q wordcloud\n",
    "import wordcloud\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import string\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                 text  stopword_ct\n",
       "2   Iâ€™ve been using furbo for 2.5 weeks now. It ha...          358\n",
       "54  Ok, ive finally gotten frustrated for the last...          253\n",
       "64  This thing is worth every penny.Bought it beca...          203"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>stopword_ct</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>Iâ€™ve been using furbo for 2.5 weeks now. It ha...</td>\n      <td>358</td>\n    </tr>\n    <tr>\n      <th>54</th>\n      <td>Ok, ive finally gotten frustrated for the last...</td>\n      <td>253</td>\n    </tr>\n    <tr>\n      <th>64</th>\n      <td>This thing is worth every penny.Bought it beca...</td>\n      <td>203</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# Create stopword count feature\n",
    "df['stopword_ct'] = df.text.apply(lambda x: len([x for x in x.split() if x in stop]))\n",
    "\n",
    "# See 3 rows\n",
    "df[['text','stopword_ct']].sort_values('stopword_ct',ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                 text  punctuation_ct\n",
       "14  EDIT:I am very pleased with their customer sup...              76\n",
       "2   Iâ€™ve been using furbo for 2.5 weeks now. It ha...              62\n",
       "64  This thing is worth every penny.Bought it beca...              53"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>punctuation_ct</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>14</th>\n      <td>EDIT:I am very pleased with their customer sup...</td>\n      <td>76</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Iâ€™ve been using furbo for 2.5 weeks now. It ha...</td>\n      <td>62</td>\n    </tr>\n    <tr>\n      <th>64</th>\n      <td>This thing is worth every penny.Bought it beca...</td>\n      <td>53</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# Create punctuation count feature\n",
    "def count_punct(text):\n",
    "    count = sum([1 for char in text if char in string.punctuation])\n",
    "    return count\n",
    "\n",
    "df['punctuation_ct'] = df.text.apply(lambda x: count_punct(x))\n",
    "\n",
    "# See 3 rows\n",
    "df[['text', 'punctuation_ct']].sort_values('punctuation_ct',ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                  text  hashtag_ct\n",
       "0    I bought the Furbo as a birthday gift for my b...           0\n",
       "336  Great product and impeccable customer service....           0\n",
       "334  I bought this on sale and I love it! Being abl...           0"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>hashtag_ct</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I bought the Furbo as a birthday gift for my b...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>336</th>\n      <td>Great product and impeccable customer service....</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>334</th>\n      <td>I bought this on sale and I love it! Being abl...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "# Create hashtag count feature\n",
    "df['hashtag_ct'] = df.text.apply(lambda x: len([x for x in x.split() if x.startswith('#')]))\n",
    "\n",
    "# See 3 rows\n",
    "df[['text','hashtag_ct']].sort_values('hashtag_ct',ascending=False).head(3)\n",
    "\n",
    "# How many times where hashtag is not 0?\n",
    "# df.hastag_ct.loc[df.hastag_ct != 0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                 text  numeric_ct\n",
       "76  Love the furbo! I can access the camera easily...           3\n",
       "3   I had REALLY high hopes for this product since...           3\n",
       "6   Excellent camera. Works great as a security ca...           3"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>numeric_ct</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>76</th>\n      <td>Love the furbo! I can access the camera easily...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>I had REALLY high hopes for this product since...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Excellent camera. Works great as a security ca...</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "# Create numeric count feature\n",
    "df['numeric_ct'] = df.text.apply(lambda x: len([x for x in x.split() if x.isdigit()]))\n",
    "\n",
    "# See 3 rows\n",
    "df[['text','numeric_ct']].sort_values('numeric_ct',ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                 text  uppercase_ct\n",
       "2   Iâ€™ve been using furbo for 2.5 weeks now. It ha...            32\n",
       "46  I am a person who is so bonded to my golden re...            21\n",
       "24  I put off buying this because of the price, bu...            20"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>uppercase_ct</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>Iâ€™ve been using furbo for 2.5 weeks now. It ha...</td>\n      <td>32</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>I am a person who is so bonded to my golden re...</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>I put off buying this because of the price, bu...</td>\n      <td>20</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "# Create an uppercase count feature\n",
    "df['uppercase_ct'] = df.t.apply(lambda x: len([x for x in x.split() if x.isupper()]))\n",
    "\n",
    "# See 3 rows\n",
    "df[['text','uppercase_ct']].sort_values('uppercase_ct',ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO Right now, this code gets distinct number of emojis... \n",
    "#TODO Change to total number of emojis used\n",
    "\n",
    "# Load libraries for emoji & regex\n",
    "import emoji\n",
    "import regex\n",
    "import re\n",
    "import advertools as adv\n",
    "\n",
    "# Define function to remove emojis\n",
    "def count_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags \n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.findall(text)\n",
    "\n",
    "# Emoji count \n",
    "df['emoji_ct'] = df.text.apply(lambda x: len(count_emoji(x)))\n",
    "\n",
    "\n",
    "# Write a function to identify all the emojis, call it emoji_ct\n",
    "#df['emoji_ct'] = df['text'].apply(lambda x: len([x for x in x.split() if x.isupper()]))\n",
    "\n",
    "# See 3 rows\n",
    "df[['text','emoji_ct']].sort_values('emoji_ct',ascending=False).head(10)\n",
    "\n",
    "df.to_csv(r'df-test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a function to identify all the emoticons, call it emoticon_ct\n",
    "\n",
    "# See 3 rows\n",
    "# df[['text','emoticon_ct']].head(3)\n",
    "\n"
   ]
  },
  {
   "source": [
    "## Part 3: Data & Text Cleaning\n",
    "* Change to lower case\n",
    "* Remove punctuation, stopwords, URLs, html tags, emojis, emoticons\n",
    "* Spell correction\n",
    "* Explore & remove custom stopwords"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column called \"text_clean\"\n",
    "df['text_clean'] = df.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    i bought the furbo as a birthday gift for my b...\n",
       "1    extremely disappointed. i recieved a furbo tha...\n",
       "2    iâ€™ve been using furbo for 2.5 weeks now. it ha...\n",
       "Name: text_clean, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "# Convert all to lowercase\n",
    "df['text_clean'] = df.text_clean.apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "\n",
    "# See 3 rows\n",
    "df.text_clean.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-28-54baf41180ce>:2: FutureWarning: The default value of regex will change from True to False in a future version.\n  df['text_clean'] = df.text_clean.str.replace('[^\\w\\s]','')\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    i bought the furbo as a birthday gift for my b...\n",
       "1    extremely disappointed i recieved a furbo that...\n",
       "2    ive been using furbo for 25 weeks now it has d...\n",
       "Name: text_clean, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "# Remove punctuation\n",
    "df['text_clean'] = df.text_clean.str.replace('[^\\w\\s]','')\n",
    "\n",
    "# See 3 rows\n",
    "df.text_clean.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "19     honestly buy waste money first 200 upfront non...\n",
       "291    absolutely love camera actually dont use pat u...\n",
       "382         awesome product two dogs love getting treats\n",
       "374    dog loves treats also doubles additional secur...\n",
       "49     camera works great notifications accuratehowev...\n",
       "245    good system easy set thing sucks yhe treats ne...\n",
       "190    product works really well get allot enjoyment ...\n",
       "325    love small dog though 6lbs treats quite small ...\n",
       "252    great helps dog feel safe gone everyone know t...\n",
       "82     bought gift love itpro says works great securi...\n",
       "Name: text_clean, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "# Library to identify stopwords\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Define english & french stopwords \n",
    "stop = stopwords.words('english')\n",
    "stop2 = stopwords.words('french')\n",
    "\n",
    "# Remove english & french stopwords\n",
    "df['text_clean'] = df.text_clean.apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "df['text_clean'] = df.text_clean.apply(lambda x: \" \".join(x for x in x.split() if x not in stop2))\n",
    "\n",
    "# See 10 rows\n",
    "df.text_clean.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    bought furbo birthday gift boyfriend absolutel...\n",
       "1    extremely disappointed recieved furbo clearly ...\n",
       "2    ive using furbo 25 weeks done much maltipoo st...\n",
       "Name: text_clean, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "# Load libraries\n",
    "import re\n",
    "import string\n",
    "\n",
    "# Define function to remove URLs\n",
    "def remove_url(text):\n",
    "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url.sub(r'', text)\n",
    "\n",
    "# Remove the test\n",
    "df['text_clean'] = df.text_clean.apply(lambda x: remove_url(x))\n",
    "\n",
    "# See 3 rows\n",
    "df.text_clean.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    bought furbo birthday gift boyfriend absolutel...\n",
       "1    extremely disappointed recieved furbo clearly ...\n",
       "2    ive using furbo 25 weeks done much maltipoo st...\n",
       "Name: text_clean, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "# Define function to remove HTML tags\n",
    "def remove_html(text):\n",
    "    html=re.compile(r'<.*?>')\n",
    "    return html.sub(r'',text)\n",
    "\n",
    "# Remove all html tags\n",
    "df['text_clean'] = df.text_clean.apply(lambda x: remove_html(x))\n",
    "\n",
    "# See 3 rows\n",
    "df.text_clean.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    bought furbo birthday gift boyfriend absolutel...\n",
       "1    extremely disappointed recieved furbo clearly ...\n",
       "2    ive using furbo 25 weeks done much maltipoo st...\n",
       "Name: text_clean, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "# Define function to remove emojis --> e.g. ðŸ˜œ\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags \n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "# Remove all emojis\n",
    "df['text_clean'] = df.text_clean.apply(lambda x: remove_emoji(x))\n",
    "\n",
    "# See 3 rows\n",
    "df.text_clean.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: emot in c:\\users\\domen\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.1)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    bought furbo birthday gift boyfriend absolutel...\n",
       "1    extremely disappointed recieved furbo clearly ...\n",
       "2    ive using furbo 25 weeks done much maltipoo st...\n",
       "Name: text_clean, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "# Define function to remove emoticons --> e.g. :-)\n",
    "\n",
    "# Libraries\n",
    "!pip install emot\n",
    "from emot.emo_unicode import UNICODE_EMO, EMOTICONS\n",
    "\n",
    "# Function for removing emoticons\n",
    "def remove_emoticons(text):\n",
    "    emoticon_pattern = re.compile(u'(' + u'|'.join(k for k in EMOTICONS) + u')')\n",
    "    return emoticon_pattern.sub(r'', text)\n",
    "\n",
    "# Remove all emoticons\n",
    "df['text_clean'] = df.text_clean.apply(lambda x: remove_emoticons(x))\n",
    "\n",
    "# See 3 rows\n",
    "df.text_clean.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0    bought furbo birthday gift boyfriend absolutel...\n",
       "1    extremely disappointed recieved furbo clearly ...\n",
       "2    ive using furbo 25 weeks done much maltipoo st...\n",
       "Name: text_clean, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "#TODO Check to see if this worked as intended...\n",
    "# Spell correction \n",
    "from textblob import TextBlob\n",
    "df['text_clean'][:5].apply(lambda x: str(TextBlob(x).correct()))\n",
    "\n",
    "# See 3 rows\n",
    "df.text_clean.head(3)"
   ]
  },
  {
   "source": [
    "## Part 4: Feature Extraction (after text cleaning)\n",
    "* Word count\n",
    "* Character count\n",
    "* Avg/median word length\n",
    "* Create date/time variable\n",
    "* Create review country\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Part 5: Save Data\n",
    "* Save cleaned data to CSV"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find the polarity of each review\n",
    "def polarity(x):\n",
    "    pol = TextBlob(x).sentiment.polarity\n",
    "    df['polarity'] = x['text'].apply(pol) # depending on the size of your data, this step may take some time.\n",
    "    return df\n",
    "\n",
    "polarity()"
   ]
  }
 ]
}